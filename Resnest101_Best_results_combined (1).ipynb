{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install Required Libraries\n",
        "!pip install -q kaggle timm scikit-learn albumentations tqdm\n",
        "!pip install -q torch torchvision"
      ],
      "metadata": {
        "id": "r69WpMP0yXwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "JlWpNindyZ-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Import Libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim  # <-- THIS WAS MISSING\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import timm  # For ResNeSt-101"
      ],
      "metadata": {
        "id": "mTmpE9A5yduW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: Load ISIC 2019 Malignant Metadata\n",
        "gt_2019 = pd.read_csv('/content/drive/MyDrive/PW2/ISIC_2019_Training_GroundTruth.csv')\n",
        "meta_2019 = pd.read_csv('/content/drive/MyDrive/PW2/ISIC_2019_Training_Metadata.csv')\n",
        "\n",
        "# ✅ Filter malignant images only (MEL == 1)\n",
        "gt_2019['target'] = gt_2019['MEL']\n",
        "malignant_2019 = gt_2019[gt_2019['target'] == 1]\n",
        "malignant_2019 = pd.merge(malignant_2019, meta_2019, on='image')\n",
        "malignant_2019['image_path'] = malignant_2019['image'].apply(\n",
        "    lambda x: f\"/content/drive/MyDrive/PW2/ISIC_2019_Malignant_Images/{x}.jpg\")"
      ],
      "metadata": {
        "id": "CrvZuKVsygjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: Load ISIC 2020 Metadata\n",
        "meta_2020 = pd.read_csv('/content/drive/MyDrive/PW2/metadata.csv')\n",
        "meta_2020['image_path'] = meta_2020['image_name'].apply(\n",
        "    lambda x: f\"/content/drive/MyDrive/PW2/dataset/train/{x}.jpg\")\n",
        "meta_2020.rename(columns={\n",
        "    'image_name': 'image',\n",
        "    'anatom_site_general_challenge': 'anatom_site_general'\n",
        "}, inplace=True)"
      ],
      "metadata": {
        "id": "QK-BE9xByit4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Handle Missing Values\n",
        "for df in [malignant_2019, meta_2020]:\n",
        "    df['age_approx'].fillna(df['age_approx'].mean(), inplace=True)\n",
        "    df['sex'].fillna('unknown', inplace=True)\n",
        "    df['anatom_site_general'].fillna('unknown', inplace=True)"
      ],
      "metadata": {
        "id": "6OrLus8ZylDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: Combine Malignant Images from 2019 and 2020\n",
        "malignant_2020 = meta_2020[meta_2020['target'] == 1]\n",
        "all_malignant = pd.concat([malignant_2019, malignant_2020], ignore_index=True)\n",
        "\n",
        "# ✅ Balance by undersampling benign cases from 2020\n",
        "benign_2020 = meta_2020[meta_2020['target'] == 0].sample(len(all_malignant), random_state=42)\n",
        "\n",
        "# # ✅ Combine and shuffle the dataset\n",
        "# balanced_data = pd.concat([all_malignant, benign_2020]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "# print(f\"📊 Total dataset size after balancing: {len(balanced_data)}\")\n"
      ],
      "metadata": {
        "id": "NhYOrrcEyms1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Use all available benign images for a larger dataset\n",
        "benign_2020 = meta_2020[meta_2020['target'] == 0]\n",
        "balanced_data = pd.concat([all_malignant, benign_2020]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"📊 Total dataset size (all malignant + all benign): {len(balanced_data)}\")\n"
      ],
      "metadata": {
        "id": "KJCWK95Gsy97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 8: Encode Categorical Features & Scale Age\n",
        "label_encoders = {\n",
        "    'sex': LabelEncoder().fit(balanced_data['sex'].astype(str)),\n",
        "    'anatom_site_general': LabelEncoder().fit(balanced_data['anatom_site_general'].astype(str))\n",
        "}\n",
        "for col, le in label_encoders.items():\n",
        "    balanced_data[col] = le.transform(balanced_data[col].astype(str))\n",
        "\n",
        "scaler = StandardScaler().fit(balanced_data[['age_approx']])\n",
        "balanced_data[['age_approx']] = scaler.transform(balanced_data[['age_approx']])\n",
        "# Replace NaN patient_id with unique identifiers\n",
        "import numpy as np\n",
        "\n",
        "# ✅ Assign unique IDs for missing patient_id entries\n",
        "balanced_data['patient_id'] = np.where(\n",
        "    balanced_data['patient_id'].isnull(),\n",
        "    'unknown_' + balanced_data.index.astype(str),\n",
        "    balanced_data['patient_id']\n",
        ")\n"
      ],
      "metadata": {
        "id": "jeNgh8bgynUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.15, random_state=42)\n",
        "train_idx, test_idx = next(gss.split(balanced_data, groups=balanced_data['patient_id']))\n",
        "\n",
        "train_val_data = balanced_data.iloc[train_idx]\n",
        "test = balanced_data.iloc[test_idx]\n",
        "\n",
        "# Further split train_val_data into train and validation\n",
        "gss_val = GroupShuffleSplit(n_splits=1, test_size=0.15, random_state=42)\n",
        "train_idx, val_idx = next(gss_val.split(train_val_data, groups=train_val_data['patient_id']))\n",
        "\n",
        "train = train_val_data.iloc[train_idx]\n",
        "val = train_val_data.iloc[val_idx]\n",
        "\n",
        "# ✅ Check for overlaps again\n",
        "print(f\"Train-Test Patient Overlap: {len(set(train['patient_id']).intersection(set(test['patient_id'])))}\")\n",
        "print(f\"Train-Val Patient Overlap: {len(set(train['patient_id']).intersection(set(val['patient_id'])))}\")\n",
        "print(f\"Val-Test Patient Overlap: {len(set(val['patient_id']).intersection(set(test['patient_id'])))}\")\n"
      ],
      "metadata": {
        "id": "3-8OCjnSyplk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# STEP 1: Save train, val, test datasets\n",
        "joblib.dump(train, '/content/drive/MyDrive/PW2/train_dataset.pkl')\n",
        "joblib.dump(val, '/content/drive/MyDrive/PW2/val_dataset.pkl')\n",
        "joblib.dump(test, '/content/drive/MyDrive/PW2/test_dataset.pkl')\n",
        "print(\"✅ Datasets saved successfully!\")"
      ],
      "metadata": {
        "id": "NWW7lr_PfyN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 10: Dataset Class (Handles OSError and Missing Files)\n",
        "class ISICDatasetWithMeta(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.data = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        while True:\n",
        "            img_path = self.data.iloc[idx]['image_path']\n",
        "            try:\n",
        "                image = Image.open(img_path).convert(\"RGB\")\n",
        "                if self.transform:\n",
        "                    image = self.transform(image)\n",
        "                sex = float(self.data.iloc[idx]['sex'])\n",
        "                age = float(self.data.iloc[idx]['age_approx'])\n",
        "                site = float(self.data.iloc[idx]['anatom_site_general'])\n",
        "                meta_data = torch.tensor([sex, age, site], dtype=torch.float32)\n",
        "                label = torch.tensor(self.data.iloc[idx]['target'], dtype=torch.float32)\n",
        "                return image, meta_data, label\n",
        "            except (FileNotFoundError, UnidentifiedImageError, OSError) as e:\n",
        "                print(f\"⚠️ Error loading file {img_path}: {e}. Skipping...\")\n",
        "                idx = (idx + 1) % len(self.data)"
      ],
      "metadata": {
        "id": "lhrCwcbDysOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 11: Data Transformations\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ],
      "metadata": {
        "id": "geoGMCEkywax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 12: DataLoaders\n",
        "# Increase batch_size to 32 or 64 depending on GPU memory\n",
        "train_loader = DataLoader(ISICDatasetWithMeta(train, train_transforms), batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(ISICDatasetWithMeta(val, val_test_transforms), batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(ISICDatasetWithMeta(test, val_test_transforms), batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "zd6pWb3Yyzek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 13: ResNeSt-101 Model\n",
        "class ResNeSt101Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.base_model = timm.create_model('resnest101e', pretrained=True, num_classes=0, global_pool='avg')\n",
        "        self.meta_fc = nn.Sequential(\n",
        "            nn.Linear(3, 32), nn.BatchNorm1d(32), nn.ReLU(), nn.Dropout(0.3)\n",
        "        )\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(self.base_model.num_features + 32, 256),\n",
        "            nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, meta):\n",
        "        x = self.base_model(x)\n",
        "        meta = self.meta_fc(meta)\n",
        "        x = torch.cat([x, meta], dim=1)\n",
        "        return self.head(x).squeeze()"
      ],
      "metadata": {
        "id": "gBXaLql-y1n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 14: Training Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNeSt101Model().to(device)\n",
        "\n",
        "num_neg = len(train[train['target'] == 0])\n",
        "num_pos = len(train[train['target'] == 1])\n",
        "pos_weight = torch.tensor([num_neg / num_pos]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "0eI-GMlty6kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 15: Training Loop (Best Model Saved to Drive)\n",
        "drive_model_path = '/content/drive/MyDrive/PW2/models/ResNeSt101_BestModel_combined_improved.pth'\n",
        "os.makedirs(os.path.dirname(drive_model_path), exist_ok=True)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=10):\n",
        "    best_f1 = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for images, meta, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            images, meta, labels = images.to(device), meta.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images, meta)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_preds, val_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, meta, labels in val_loader:\n",
        "                images, meta = images.to(device), meta.to(device)\n",
        "                outputs = torch.sigmoid(model(images, meta))\n",
        "                val_preds.extend(outputs.cpu().numpy())\n",
        "                val_labels.extend(labels.numpy())\n",
        "\n",
        "        val_preds_binary = (np.array(val_preds) > 0.5).astype(int)\n",
        "        val_f1 = f1_score(val_labels, val_preds_binary)\n",
        "        val_auc = roc_auc_score(val_labels, val_preds)\n",
        "        print(f\"📈 Epoch {epoch+1} Validation F1 Score: {val_f1:.4f}, Validation ROC AUC: {val_auc:.4f}\")\n",
        "\n",
        "        # Save the model if F1 score improves\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            torch.save(model.state_dict(), drive_model_path)\n",
        "            print(f\"✅ New best model saved with F1 score: {best_f1:.4f}\")\n",
        "\n",
        "    print(f\"🏆 Best Validation F1 Score achieved: {best_f1:.4f}\")\n",
        "\n",
        "train_model(model, train_loader, val_loader, epochs=10)"
      ],
      "metadata": {
        "id": "z1eIwNx7y9gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 16: Evaluation\n",
        "model.load_state_dict(torch.load(drive_model_path))\n",
        "model.eval()\n",
        "\n",
        "test_preds, test_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for images, meta, labels in test_loader:\n",
        "        images, meta = images.to(device), meta.to(device)\n",
        "        outputs = torch.sigmoid(model(images, meta))\n",
        "        test_preds.extend(outputs.cpu().numpy())\n",
        "        test_labels.extend(labels.numpy())\n",
        "\n",
        "test_preds = (np.array(test_preds) > 0.5).astype(int)\n",
        "auc = roc_auc_score(test_labels, test_preds)\n",
        "acc = accuracy_score(test_labels, test_preds)\n",
        "recall = recall_score(test_labels, test_preds)\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "print(f\"\\n📊 **Final Evaluation on Test Set**:\")\n",
        "print(f\"AUC-ROC: {auc:.4f}\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Sensitivity (Recall): {recall:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "szc3uVnwy-Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, RocCurveDisplay, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# STEP 1: Compute probabilities for ROC\n",
        "model.eval()\n",
        "test_preds_proba, test_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for images, meta, labels in test_loader:\n",
        "        images, meta = images.to(device), meta.to(device)\n",
        "        outputs = torch.sigmoid(model(images, meta))\n",
        "        test_preds_proba.extend(outputs.cpu().numpy())\n",
        "        test_labels.extend(labels.numpy())\n",
        "\n",
        "# STEP 2: Plot ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(test_labels, test_preds_proba)\n",
        "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
        "plt.title('📈 ROC Curve')\n",
        "plt.show()\n",
        "\n",
        "# STEP 3: Compute Confusion Matrix\n",
        "test_preds = (np.array(test_preds_proba) > 0.5).astype(int)\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Benign', 'Malignant'])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('📊 Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Optional: Print confusion matrix details\n",
        "print(f\"Confusion Matrix:\\n{cm}\")\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n",
        "print(f\"True Positives (TP): {tp}\")\n"
      ],
      "metadata": {
        "id": "NUz1oADJoB70"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}